{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDStandardScaler(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = StandardScaler(copy=True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "\n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input feature dataset\n",
    "features = scipy.io.loadmat('./feature_vector.mat')\n",
    "\n",
    "rans = np.arange(7165)\n",
    "# Turn feature dataset into seperate arrays\n",
    "AEVs = np.transpose(np.array(features['AEVs']), (2, 0, 1))\n",
    "Atomic_Num = np.array(features['Atomic_Num'], dtype=np.long)\n",
    "Target = np.array(features['labels'][0])\n",
    "\n",
    "AEVs = np.round(AEVs,4)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(np.shape(AEVs))\n",
    "print(np.shape(Atomic_Num))\n",
    "print(np.shape(Target))\n",
    "print(AEVs[50][2][41:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ar= AEVs\n",
    "scaler = NDStandardScaler()\n",
    "data = scaler.fit_transform(Ar)\n",
    "AEVs = data\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[50][3][280:320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(520, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128,64)\n",
    "        self.fc5 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        x = (self.fc5(x))\n",
    "        #print(x)\n",
    "        return x #need activation function on x or loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doNN():\n",
    "    # Declare Nets\n",
    "    NNP_H = Net()\n",
    "    NNP_C = Net()\n",
    "    NNP_N = Net()\n",
    "    NNP_O = Net()\n",
    "    NNP_S = Net()\n",
    "    \n",
    "    # put in a list for ease of access\n",
    "    nets = [NNP_H, NNP_C, NNP_N, NNP_O, NNP_S]\n",
    "    \n",
    "    Los = []\n",
    "    \n",
    "    # corresponding optimizers\n",
    "    optimizers = []\n",
    "    #criterions = []\n",
    "    for net in nets:\n",
    "        optimizers.append( optim.Adam(net.parameters(), lr=0.0099,betas=(0.5,0.59) ,eps=1e-08))\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "        \n",
    "    ##########################################################################################\n",
    "    # training\n",
    "    epochs = 20\n",
    "    molecules = 5000\n",
    "    batch_size = 20\n",
    "    rep = int(molecules/batch_size)\n",
    "    \n",
    "    for epoch in range(epochs) :\n",
    "        print(\"epoch: \", epoch)\n",
    "        \n",
    "        for mols in range(rep) :\n",
    "            \n",
    "            outp = torch.zeros(1,batch_size)\n",
    "            toget = torch.zeros(1,batch_size)\n",
    "            ck = int(0)\n",
    "            \n",
    "            start = mols*batch_size\n",
    "            \n",
    "            for mole in range(start,start+batch_size):\n",
    "                molecule = int(rans[int(mole)])\n",
    "                molecule = mole\n",
    "\n",
    "                out_f = torch.zeros(1,1)\n",
    "\n",
    "                # use all relevant aev's on the relevant nets\n",
    "                for atom in range(23):\n",
    "                    if(Atomic_Num[molecule][atom]==0):\n",
    "                        continue\n",
    "\n",
    "                    aev = torch.from_numpy(AEVs[molecule][atom])\n",
    "                    out = nets[Atomic_Num[molecule][atom]-1](aev.float())\n",
    "                    out_f = out_f + out\n",
    "\n",
    "                outp[0][ck] = out_f\n",
    "                \n",
    "                targett = Target[molecule]\n",
    "                targett = torch.from_numpy(np.array(targett))\n",
    "                targett = targett.float()\n",
    "                toget[0][ck] = targett\n",
    "                ck = int(ck+1)\n",
    "                \n",
    "                # Get a list of only the nets that were used. I.e list of atoms in the molecule\n",
    "                used_atoms = []\n",
    "                for atom in range(23):\n",
    "                    if(Atomic_Num[molecule][atom]!=0):\n",
    "                        used_atoms.append(Atomic_Num[molecule][atom])\n",
    "                used_atoms = np.unique(np.array(used_atoms))\n",
    "            \n",
    "                # if no nets were used, just move on to the next molecule\n",
    "                if(len(used_atoms)==0) :\n",
    "                    print(\"scream\")\n",
    "                    break\n",
    "                \n",
    "            # setting the parameters for the entire net to be zero\n",
    "            for net in nets:\n",
    "                net.zero_grad()\n",
    "            \n",
    "            for optimizer in optimizers:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            toget = toget.view(1,-1)\n",
    "            \n",
    "            # use loss function\n",
    "            loss = criterion(outp,toget)\n",
    "\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            \n",
    "            # step only the used optimizers            \n",
    "            for atom in range(5) :\n",
    "                optimizers[atom].step()\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    # Testing\n",
    "    losses = []\n",
    "    answ = 0\n",
    "    for mole in range(5501,7100) :\n",
    "        molecule = int(rans[int(mole)])\n",
    "        molecule = mole\n",
    "        \n",
    "\n",
    "        molecule_out = torch.zeros(1,1)\n",
    "        for atom in range(23):\n",
    "            if(Atomic_Num[molecule][atom]==0):\n",
    "                continue\n",
    "            aev = torch.from_numpy((AEVs[molecule][atom]))\n",
    "            net_out = nets[Atomic_Num[molecule][atom]-1](aev.float())\n",
    "            molecule_out = molecule_out + net_out\n",
    "        \n",
    "        targett = Target[molecule]\n",
    "        targett = torch.from_numpy(np.array(targett))\n",
    "        targett = targett.float()\n",
    "        targett = targett.view(1, -1)\n",
    "        \n",
    "        loss = criterion(molecule_out, targett)\n",
    "        if ((targett-15) <= molecule_out <= (targett+15)) :\n",
    "            answ = answ + 1\n",
    "        \n",
    "    print(answ)\n",
    "    \n",
    "doNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "for molecule in range(10):\n",
    "    for atom in range(23):\n",
    "        aev = []\n",
    "        for elem in AEVs[molecule][atom]:\n",
    "            if(elem>0.0000000001):\n",
    "                aev.append(elem)\n",
    "        print(aev)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
