{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(520, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x #need activation function on x or loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "(7165, 23, 520)\n",
      "(7165, 23)\n",
      "(7165,)\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Get input feature dataset\n",
    "features = scipy.io.loadmat('./feature_vector 2.mat')\n",
    "\n",
    "\n",
    "# Turn feature dataset into seperate arrays\n",
    "AEVs = np.transpose(np.array(features['AEVs']), (2, 0, 1))\n",
    "Atomic_Num = np.array(features['Atomic_Num'], dtype=np.long)\n",
    "Target = np.array(features['labels'][0])\n",
    "'''\n",
    "\n",
    "AEVs = np.random.rand(7165, 23, 520)\n",
    "Atomic_Num = np.random.randint(6, size=(7165, 23))\n",
    "Target = np.random.rand(7165)\n",
    "'''\n",
    "print(\"Shapes:\")\n",
    "print(np.shape(AEVs))\n",
    "print(np.shape(Atomic_Num))\n",
    "print(np.shape(Target))\n",
    "\n",
    "list_atoms = []\n",
    "for row in Atomic_Num:\n",
    "    for elem in row:\n",
    "        list_atoms.append(elem)\n",
    "print(np.unique(np.array(list_atoms)))\n",
    "\n",
    "# Seperate into training and testing samples\n",
    "#train_atoms =    \n",
    "#train_samples = \n",
    "#train_labels = \n",
    "\n",
    "#test_atoms = \n",
    "#test_samples = \n",
    "#test_labels = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1249.4500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1561125.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1249.4500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1100.5900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1211298.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1100.5900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-945.6100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(894178.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-945.6100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1400.2900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1960812.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1400.2900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1600.2700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2560864.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1600.2700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1123.3199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1261847.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1123.3199]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1258.4600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1583721.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1258.4600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1132.0100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1281446.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1132.0100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1258.2800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1583268.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1258.2800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1131.6400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1280609.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1131.6400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1401.1200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1963137.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1401.1200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1406.4700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1978157.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1406.4700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1270.0601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1613052.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1270.0601]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1104.1899]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1219235.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1104.1899]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 4 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-972.4900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(945736.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-972.4900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1194.1600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1426018.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1194.1600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1602.2800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2567301.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1602.2800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1751.2000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3066701.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1751.2000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1595.9500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2547056.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1595.9500]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1317.0800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1734699.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1317.0800]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1230.1400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1513244.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1230.1400]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1213.2400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1471951.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1213.2400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1468.]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2155024., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1468.]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1462.7400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2139608.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1462.7400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1482.8000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2198696., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1482.8000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1485.7600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2207482.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1485.7600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1750.7000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3064950.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1750.7000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1484.8700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2204839., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1484.8700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1488.4700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2215542.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1488.4700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1343.7600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1805691., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1343.7600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1348.1000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1817373.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1348.1000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1496.5200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2239572.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1496.5200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1257.1300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1580375.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1257.1300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1639.5800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2688222.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1639.5800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1242.6700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1544228.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1242.6700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1105.6700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1222506.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1105.6700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1217.2300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1481648.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1217.2300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1750.5300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3064355.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1750.5300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1472.]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2166784., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1472.]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1124.1500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1263713.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1124.1500]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1503.9800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2261955.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1503.9800]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 3 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1129.2600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1275228.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1129.2600]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1383.1100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1912993.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1383.1100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1206.6801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1456076.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1206.6801]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1363.9900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1860468.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1363.9900]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1335.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1784174.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1335.7300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1481.1700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2193864.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1481.1700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1484.5000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2203740.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1484.5000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1748.5601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3057462.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1748.5601]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1353.0200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1830663.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1353.0200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1220.2300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1488961.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1220.2300]], grad_fn=<SubBackward0>)\n",
      "2 3 3 2 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1220.9900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1490816.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1220.9900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.3500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2628775.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.3500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.3600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2628808.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.3600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1361.0200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1852375.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1361.0200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1615.5500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2610002., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1615.5500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1622.2100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2631565.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1622.2100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1619.7000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2623428., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1619.7000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1637.3800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2681013.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1637.3800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1750.7400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3065090.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1750.7400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.1801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2628224.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.1801]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.3199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2628678.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.3199]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1387.3700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1924795.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1387.3700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1612.5601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2600350., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1612.5601]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1613.9500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2604834.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1613.9500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1635.9399]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2676299.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1635.9399]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1492.6000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2227854.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1492.6000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1497.0699]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2241218.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1497.0699]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1614.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2608128., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1614.9700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1620.3101]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2625404.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1620.3101]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1749.3600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3060260.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1749.3600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1386.1100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1921300.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1386.1100]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1255.9399]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1577385.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1255.9399]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1363.6899]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1859650.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1363.6899]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1347.8900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1816807.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1347.8900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1324.3300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1753849.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1324.3300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1614.8900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2607869.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1614.8900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1489.5800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2218848.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1489.5800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1620.5400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2626150., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1620.5400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1608.8000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2588237.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1608.8000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1242.7100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1544328., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1242.7100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1750.3500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3063725., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1750.3500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1487.9200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2213906., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1487.9200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1381.6801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1909039.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1381.6801]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1266.0200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1602806.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1266.0200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1082.2000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1171156.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1082.2000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1222.7200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1495044.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1222.7200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1223.3500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1496585.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1223.3500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1361.9800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1854989.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1361.9800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1253.8800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1572215.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1253.8800]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1620.8800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2627252., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1620.8800]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1471.2700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2164635.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1471.2700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1895.9100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3594474.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1895.9100]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1317.1700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1734936.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1317.1700]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1490.7500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2222335.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1490.7500]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1225.4700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1501776.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1225.4700]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1481.8600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2195909., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1481.8600]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1490.5601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2221769.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1490.5601]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1622.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2634031.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1622.9700]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1494.9200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2234786., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1494.9200]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1385.7200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1920219.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1385.7200]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1267.4399]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1606404., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1267.4399]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1486.8900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2210842., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1486.8900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1894.9600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3590873.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1894.9600]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1366.6400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1867704.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1366.6400]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1230.0601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1513047.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1230.0601]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1620.2600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2625242.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1620.2600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1617.8101]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2617309.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1617.8101]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1469.6200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2159783., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1469.6200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1314.5100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1727936.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1314.5100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1619.0500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2621323., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1619.0500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1612.3500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2599672.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1612.3500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1611.4500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2596771., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1611.4500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1464.0400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2143413.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1464.0400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1894.9100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3590684., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1894.9100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1311.9000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1721081.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1311.9000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1619.4200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2622521.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1619.4200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1623.3800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2635362.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1623.3800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1615.8700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2611035.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1615.8700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1471.8800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2166430.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1471.8800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1314.5000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1727910.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1314.5000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1473.0100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2169758.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1473.0100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1472.8199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2169198.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1472.8199]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1617.9500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2617762., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1617.9500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1320.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1744961.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1320.9700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1896.0300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3594929.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1896.0300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1600.7500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2562400.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1600.7500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1766.6000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3120875.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1766.6000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1058.3400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1120083.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1058.3400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1224.2200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1498714.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1224.2200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1220.4399]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1489473.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1220.4399]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1053.9399]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1110789.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1053.9399]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1360.5699]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1851150.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1360.5699]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1062.6700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1129267.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1062.6700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-884.1700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(781756.5625, grad_fn=<MseLossBackward>)\n",
      "tensor([[-884.1700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1204.1200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1449905., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1204.1200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1624.7900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2639942.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1624.7900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1896.0300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3594929.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1896.0300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1625.8900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2643518.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1625.8900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1365.7700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1865327.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1365.7700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1625.6000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2642575.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1625.6000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1362.5900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1856651.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1362.5900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1624.5400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2639130.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1624.5400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1362.5500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1856542.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1362.5500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1359.4399]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1848077., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1359.4399]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1766.7000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3121228.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1766.7000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1626.3101]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2644884.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1626.3101]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1368.5300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1872874.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1368.5300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1456.0601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2120111., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1456.0601]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1767.1100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3122677.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1767.1100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1506.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2270235.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1506.7300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1767.1700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3122890., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1767.1700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1507.2300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2271742.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1507.2300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1199.5601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1438944.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1199.5601]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1472.8500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2169287., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1472.8500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1472.0800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2167019.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1472.0800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1207.0200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1456897.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1207.0200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1624.5000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2639000.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1624.5000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1364.8199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1862733.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1364.8199]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1480.5800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2192117., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1480.5800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1623.4000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2635427.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1623.4000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1363.]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1857769., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1363.]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1765.7100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3117731.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1765.7100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1768.9301]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3129113.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1768.9301]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1505.9301]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2267825.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1505.9301]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1470.0500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2161047.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1470.0500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1198.0200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1435252., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1198.0200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1768.1300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3126283.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1768.1300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1506.3000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2268939.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1506.3000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1760.2500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3098480., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1760.2500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1387.2700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1924518.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1387.2700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1760.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3101015.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1760.9700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1348.4900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1818425.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1348.4900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1377.4700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1897423.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1377.4700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1343.5500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1805126.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1343.5500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1374.2600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1888590.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1374.2600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1343.9100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1806094.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1343.9100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1485.5300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2206799.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1485.5300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1517.7700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2303625.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1517.7700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1191.4301]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1419505.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1191.4301]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1221.6600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1492453.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1221.6600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1491.1801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2223618., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1491.1801]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1489.1500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2217567.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1489.1500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1483.4700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2200683.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1483.4700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1518.1400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2304749., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1518.1400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1610.8500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2594837.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1610.8500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1464.7700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2145551.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1464.7700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1307.4600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1709451.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1307.4600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1613.1700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2602317.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1613.1700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1762.0300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3104749.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1762.0300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1622.6000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2632830.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1622.6000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1466.6500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2151062.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1466.6500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1489.2100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2217746.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1489.2100]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1753.9000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3076165.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1753.9000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.4500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2629100., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.4500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1466.6500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2151062.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1466.6500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1767.9500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3125647., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1767.9500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.9900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2630851.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.9900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1465.1899]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2146781.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1465.1899]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1754.9000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3079674., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1754.9000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-963.0400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(927446., grad_fn=<MseLossBackward>)\n",
      "tensor([[-963.0400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1361.9900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1855016.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1361.9900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1370.8300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1879174.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1370.8300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1632.1700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2663979., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1632.1700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1371.8800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1882054.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1371.8800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1246.5900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1553986.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1246.5900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1640.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2691994.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1640.7300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1510.6801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2282154.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1510.6801]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1105.9800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1223191.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1105.9800]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1636.4600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2678001.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1636.4600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1637.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2682159.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1637.7300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1508.8199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2276537.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1508.8199]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1205.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1453784.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1205.7300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1332.3900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1775263.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1332.3900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1603.5900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2571500.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1603.5900]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1351.2700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1825930.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1351.2700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1480.1200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2190755.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1480.1200]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1481.6400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2195257.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1481.6400]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1346.9600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1814301.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1346.9600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1509.6899]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2279163.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1509.6899]], grad_fn=<SubBackward0>)\n",
      "2 2 2 3 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1478.6400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2186376.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1478.6400]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1613.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2604899., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1613.9700]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1610.8700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2594902.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1610.8700]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1616.3900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2612716.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1616.3900]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1621.3300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2628710.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1621.3300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1451.0699]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2105604., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1451.0699]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1487.8199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2213608.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1487.8199]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1624.3700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2638578., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1624.3700]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1623.2100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2634810.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1623.2100]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1466.3101]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2150065.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1466.3101]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1754.8900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3079639., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1754.8900]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1763.5500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3110108.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1763.5500]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1617.0400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2614818.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1617.0400]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1459.5400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2130257.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1459.5400]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1632.2400]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2664207.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1632.2400]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1638.5601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2684879., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1638.5601]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1626.9600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2646998.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1626.9600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1615.6600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2610357.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1615.6600]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1252.0699]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1567679.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1252.0699]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1640.4000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2690912.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1640.4000]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1502.5800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2257746.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1502.5800]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1514.7100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2294346.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1514.7100]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1370.0300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1876982.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1370.0300]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1504.]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2262016., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1504.]], grad_fn=<SubBackward0>)\n",
      "2 2 3 2 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1467.0900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2152353., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1467.0900]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1329.8600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1768527.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1329.8600]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1350.0800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1822715.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1350.0800]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1354.3700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1834318.1250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1354.3700]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1351.3101]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1826038.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1351.3101]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1472.1500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2167225.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1472.1500]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1372.9000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1884854.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1372.9000]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1187.6300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1410465., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1187.6300]], grad_fn=<SubBackward0>)\n",
      "2 2 3 3 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1483.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2202166.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1483.9700]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1612.3900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2599801.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1612.3900]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1465.2200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2146869.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1465.2200]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1309.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1715392.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1309.7300]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1482.6600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2198280.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1482.6600]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1217.9700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1483450.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1217.9700]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1379.4000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1902744.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1379.4000]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1485.7200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2207363.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1485.7200]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1631.6700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2662347.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1631.6700]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1486.2800]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2209028.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1486.2800]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1249.2200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1560550.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1249.2200]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1357.4000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1842534.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1357.4000]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 3 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1257.5100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1581331.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1257.5100]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1481.4000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2194546., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1481.4000]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 3 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1373.6500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1886914.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1373.6500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1615.6801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2610422., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1615.6801]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1485.6100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2207037., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1485.6100]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1609.7300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2591230.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1609.7300]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1490.8700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2222693.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1490.8700]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1614.4500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2606448.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1614.4500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 3 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1472.9200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2169493.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1472.9200]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1613.8199]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2604414.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1613.8199]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1609.7100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2591166.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1609.7100]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1480.9301]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2193153.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1480.9301]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1610.2000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2592744., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1610.2000]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1452.8500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2110773., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1452.8500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1761.4600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3102741.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1761.4600]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1616.1899]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2612070., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1616.1899]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1458.8600]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2128272.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1458.8600]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1631.7500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2662608., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1631.7500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1618.5601]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2619736.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1618.5601]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1760.7500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(3100240.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1760.7500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1618.5300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2619639.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1618.5300]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1464.5300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2144848.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1464.5300]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1615.4200]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2609582., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1615.4200]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 2 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1460.0500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2131746.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1460.0500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1630.9000]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2659835., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1630.9000]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1362.8500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1857360., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1362.8500]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1624.5900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2639292.5000, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1624.5900]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1502.5500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2257656.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1502.5500]], grad_fn=<SubBackward0>)\n",
      "2 2 2 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1493.2900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2229915.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1493.2900]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1361.6801]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1854172.6250, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1361.6801]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1239.2300]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1535691., grad_fn=<MseLossBackward>)\n",
      "tensor([[-1239.2300]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1631.5900]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2662085.7500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1631.5900]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1368.0100]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1871451.3750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1368.0100]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1631.6700]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(2662347.2500, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1631.6700]], grad_fn=<SubBackward0>)\n",
      "2 3 2 2 2 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "molecule\n",
      "Target:  tensor([[-1369.9500]])\n",
      "Our_vl:  tensor([0.], grad_fn=<AddBackward0>)\n",
      "Loss  :  tensor(1876762.8750, grad_fn=<MseLossBackward>)\n",
      "tensor([[-1369.9500]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def doNN():\n",
    "    # Declare Nets\n",
    "    NNP_H = Net()\n",
    "    NNP_C = Net()\n",
    "    NNP_N = Net()\n",
    "    NNP_O = Net()\n",
    "    NNP_S = Net()\n",
    "    \n",
    "    # put in a list for ease of access\n",
    "    nets = [NNP_H, NNP_C, NNP_N, NNP_O, NNP_S]\n",
    "\n",
    "    # setting the parameters for the entire net to be zero\n",
    "    for net in nets:\n",
    "        net.zero_grad()\n",
    "    \n",
    "    # corresponding optimizers\n",
    "    optimizers = []\n",
    "    #criterions = []\n",
    "    for net in nets:\n",
    "        optimizers.append( optim.SGD(net.parameters(), lr=0.01, momentum = 0.9) )\n",
    "        #criterions.append(nn.MSELoss())\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # wonder if we need seperate criterions\n",
    "    #criterion = nn.MSELoss()\n",
    "    \n",
    "    ##########################################################################################\n",
    "    # training\n",
    "    epochs = 3\n",
    "    molecules = 200\n",
    "    \n",
    "    for epoch in range(epochs) :\n",
    "        print(\"epoch: \", epoch)\n",
    "        outp = []\n",
    "            \n",
    "        for molecule in range(molecules):\n",
    "        \n",
    "            # initialize optimizer\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "            out_f = 0;\n",
    "            \n",
    "            # use all relevant aev's on the relevant nets\n",
    "            for atom in range(23):\n",
    "                #print(Atomic_Num[molecule][atom], end=\" \"),\n",
    "                if(Atomic_Num[molecule][atom]==0):\n",
    "                    continue\n",
    "                \n",
    "                aev = torch.from_numpy(AEVs[molecule][atom])\n",
    "                out = nets[Atomic_Num[molecule][atom]-1](aev.float())\n",
    "                out_f = out_f + out\n",
    "                \n",
    "                '''\n",
    "                #extra\n",
    "                targett = Target[molecule]\n",
    "                targett = torch.from_numpy(np.array(targett)\n",
    "                targett = targett.view(1,-1)\n",
    "                loss = criterion(out, targett.float())\n",
    "                loss.backward()\n",
    "                optimizers[Atomic_Num[molecule][atom]-1].step()\n",
    "                '''\n",
    "            \n",
    "            ''''''\n",
    "            targett = Target[molecule]\n",
    "            targett = torch.from_numpy(np.array(targett))\n",
    "            targett = targett.float()\n",
    "            targett = targett.view(1,-1)\n",
    "            ''''''\n",
    "            # get list of used atoms i.e NNP's\n",
    "            used_atoms = []\n",
    "            for atom in range(23):\n",
    "                if(Atomic_Num[molecule][atom]!=0):\n",
    "                    used_atoms.append(Atomic_Num[molecule][atom])\n",
    "            used_atoms = np.unique(np.array(used_atoms))\n",
    "            \n",
    "            # if no nets were used, just move on to the next molecule\n",
    "            if(len(used_atoms)==0) :\n",
    "                print(\"scream\")\n",
    "                break\n",
    "            \n",
    "            ''''''\n",
    "            # use loss function\n",
    "            loss = criterion(out_f,targett)\n",
    "\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            \n",
    "            # step only the used optimizers            \n",
    "            for atom in used_atoms:\n",
    "                optimizers[atom-1].step()    \n",
    "            ''''''\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    losses = []\n",
    "    for molecule in range(201,500) :\n",
    "\n",
    "        molecule_out = 0\n",
    "        for atom in range(23):\n",
    "            print(Atomic_Num[molecule][atom], end=\" \")\n",
    "            if(Atomic_Num[molecule][atom]==0):\n",
    "                continue\n",
    "            aev = torch.from_numpy(AEVs[molecule][atom])\n",
    "            net_out = nets[Atomic_Num[molecule][atom]-1](aev.float())\n",
    "            molecule_out = molecule_out + net_out\n",
    "        print(\"\")\n",
    "\n",
    "        targett = Target[molecule]\n",
    "        targett = torch.from_numpy(np.array(targett))\n",
    "        targett = targett.float()\n",
    "        targett = targett.view(1, -1)\n",
    "        #losses.append(targett - molecule_out)\n",
    "        loss = criterion(molecule_out, targett)\n",
    "        print(\"molecule\")\n",
    "        print(\"Target: \", targett)\n",
    "        print(\"Our_vl: \", molecule_out)\n",
    "        print(\"Loss  : \", loss)\n",
    "        print(targett - molecule_out)\n",
    "    '''\n",
    "    train(nets, optimizers, criterion)\n",
    "    testing(nets)\n",
    "    '''\n",
    "            \n",
    "    \n",
    "doNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for molecule in range(10):\n",
    "    for atom in range(23):\n",
    "        aev = []\n",
    "        for elem in AEVs[molecule][atom]:\n",
    "            if(elem>0.0000000001):\n",
    "                aev.append(elem)\n",
    "        print(aev)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
