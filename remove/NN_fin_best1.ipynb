{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDStandardScaler(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = StandardScaler(copy=True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "\n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "(7165, 23, 520)\n",
      "(7165, 23)\n",
      "(7165,)\n",
      "[0.00000e+00 9.55000e-01 6.23990e+01 1.21611e+02 2.07960e+01 1.80670e+01\n",
      " 7.98560e+01 0.00000e+00 1.57062e+02 0.00000e+00 3.21346e+02 0.00000e+00\n",
      " 2.44688e+02 5.30000e-02 5.83330e+01 0.00000e+00 4.01000e-01 0.00000e+00\n",
      " 0.00000e+00 2.31000e-01 0.00000e+00 0.00000e+00 1.20000e-02 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 8.50000e-02 1.75900e+00\n",
      " 1.35310e+01 7.00950e+01 1.24182e+02]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Get input feature dataset\n",
    "features = scipy.io.loadmat('/home/mehthab/feature_vector5.mat')\n",
    "\n",
    "rans = np.arange(7165)\n",
    "#rans = random.shuffle(rans)\n",
    "#random.shuffle(rans)\n",
    "# Turn feature dataset into seperate arrays\n",
    "AEVs = np.transpose(np.array(features['AEVs']), (2, 0, 1))\n",
    "Atomic_Num = np.array(features['Atomic_Num'], dtype=np.long)\n",
    "Target = np.array(features['labels'][0])\n",
    "'''\n",
    "\n",
    "AEVs = np.random.rand(7165, 23, 520)\n",
    "Atomic_Num = np.random.randint(6, size=(7165, 23))\n",
    "Target = np.random.rand(7165)\n",
    "\n",
    "'''\n",
    "AEVs = np.round(AEVs,4)\n",
    "#AEVs = normalize(AEVs)\n",
    "print(\"Shapes:\")\n",
    "print(np.shape(AEVs))\n",
    "print(np.shape(Atomic_Num))\n",
    "print(np.shape(Target))\n",
    "print(AEVs[50][2][41:80])\n",
    "list_atoms = []\n",
    "for row in Atomic_Num:\n",
    "    for elem in row:\n",
    "        list_atoms.append(elem)\n",
    "print(np.unique(np.array(list_atoms)))\n",
    "\n",
    "# Seperate into training and testing samples\n",
    "#train_atoms =    \n",
    "#train_samples = \n",
    "#train_labels = \n",
    "\n",
    "#test_atoms = \n",
    "#test_samples = \n",
    "#test_labels = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7165, 23, 520)\n"
     ]
    }
   ],
   "source": [
    "Ar= AEVs\n",
    "scaler = NDStandardScaler()\n",
    "data = scaler.fit_transform(Ar)\n",
    "AEVs = data\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.3606426   0.         -0.13491457 -0.32410168  0.\n",
      "  0.         -0.27383865  0.          0.          0.         -0.18444263\n",
      "  0.          0.          0.         -0.28079271  0.         -0.01670097\n",
      " -0.02434471 -0.02938443 -0.11238703 -0.14150766 -0.15390373 -0.10388758\n",
      " -0.06607923 -0.12222848  0.         -0.15160531  0.         -0.14719748\n",
      " -0.07397864 -0.11991937  0.         -0.115648    0.         -0.01700178\n",
      " -0.06798901  0.          0.         -0.0644283 ]\n"
     ]
    }
   ],
   "source": [
    "print(data[50][3][280:320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(520, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128,64)\n",
    "        self.fc5 = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        x = (self.fc5(x))\n",
    "        #print(x)\n",
    "        return x #need activation function on x or loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "1037\n"
     ]
    }
   ],
   "source": [
    "def doNN():\n",
    "    # Declare Nets\n",
    "    NNP_H = Net()\n",
    "    NNP_C = Net()\n",
    "    NNP_N = Net()\n",
    "    NNP_O = Net()\n",
    "    NNP_S = Net()\n",
    "    \n",
    "    #torch.nn.init.normal_(NNP_H.weight, mean=0, std=1)\n",
    "    #torch.nn.init.normal_(NNP_C.weight, mean=0, std=1)\n",
    "    #torch.nn.init.normal_(NNP_N.weight, mean=0, std=1)\n",
    "    #torch.nn.init.normal_(NNP_O.weight, mean=0, std=1)\n",
    "    #torch.nn.init.normal_(NNP_S.weight, mean=0, std=1)\n",
    "    \n",
    "    # put in a list for ease of access\n",
    "    nets = [NNP_H, NNP_C, NNP_N, NNP_O, NNP_S]\n",
    "    \n",
    "    Los = []\n",
    "\n",
    "        \n",
    "    # corresponding optimizers\n",
    "    optimizers = []\n",
    "    #criterions = []\n",
    "    for net in nets:\n",
    "        optimizers.append( optim.Adam(net.parameters(), lr=0.0099,betas=(0.5,0.59) ,eps=1e-08))\n",
    "        #criterions.append(nn.MSELoss())\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "    # wonder if we need seperate criterions\n",
    "    #criterion = nn.MSELoss()\n",
    "    \n",
    "    ##########################################################################################\n",
    "    # training\n",
    "    epochs = 20\n",
    "    molecules = 5000\n",
    "    batch_size = 20\n",
    "    rep = int(molecules/batch_size)\n",
    "    \n",
    "    for epoch in range(epochs) :\n",
    "        print(\"epoch: \", epoch)\n",
    "        \n",
    "        for mols in range(rep) :\n",
    "            \n",
    "            outp = torch.zeros(1,batch_size)\n",
    "            toget = torch.zeros(1,batch_size)\n",
    "            ck = int(0)\n",
    "            \n",
    "            start = mols*batch_size\n",
    "            \n",
    "            \n",
    "            for mole in range(start,start+batch_size):\n",
    "\n",
    "                # initialize optimizer\n",
    "                #for optimizer in optimizers:\n",
    "                 #   optimizer.zero_grad()\n",
    "                \n",
    "                molecule = int(rans[int(mole)])\n",
    "                molecule = mole\n",
    "\n",
    "\n",
    "                out_f = torch.zeros(1,1)\n",
    "\n",
    "                # use all relevant aev's on the relevant nets\n",
    "                for atom in range(23):\n",
    "                    #print(Atomic_Num[molecule][atom], end=\" \"),\n",
    "                    if(Atomic_Num[molecule][atom]==0):\n",
    "                        continue\n",
    "\n",
    "                    aev = torch.from_numpy(AEVs[molecule][atom])\n",
    "                    out = nets[Atomic_Num[molecule][atom]-1](aev.float())\n",
    "                    #print(\"out\", out)\n",
    "                    out_f = out_f + out\n",
    "\n",
    "                '''\n",
    "                #extra\n",
    "                targett = Target[molecule]\n",
    "                targett = torch.from_numpy(np.array(targett)\n",
    "                targett = targett.view(1,-1)\n",
    "                loss = criterion(out, targett.float())\n",
    "                loss.backward()\n",
    "                optimizers[Atomic_Num[molecule][atom]-1].step()\n",
    "                '''\n",
    "                outp[0][ck] = out_f\n",
    "                \n",
    "                #toget[ck] = Target[molecule]\n",
    "\n",
    "                targett = Target[molecule]\n",
    "                targett = torch.from_numpy(np.array(targett))\n",
    "                targett = targett.float()\n",
    "                toget[0][ck] = targett\n",
    "                #targett = targett.view(1,-1)\n",
    "                ck = int(ck+1)\n",
    "                \n",
    "                used_atoms = []\n",
    "                for atom in range(23):\n",
    "                    if(Atomic_Num[molecule][atom]!=0):\n",
    "                        used_atoms.append(Atomic_Num[molecule][atom])\n",
    "                used_atoms = np.unique(np.array(used_atoms))\n",
    "            \n",
    "            # if no nets were used, just move on to the next molecule\n",
    "                if(len(used_atoms)==0) :\n",
    "                    print(\"scream\")\n",
    "                    break\n",
    "                \n",
    "                \n",
    "            #print(\"outf\", out_f)\n",
    "            #ck = ck + 1\n",
    "            # setting the parameters for the entire net to be zero\n",
    "            for net in nets:\n",
    "                net.zero_grad()\n",
    "            \n",
    "            for optimizer in optimizers:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            \n",
    "            #targett = Target[molecule]\n",
    "            #targett = torch.from_numpy(np.array(targett))\n",
    "            #targett = targett.float()\n",
    "            #targett = targett.view(1,-1)\n",
    "            ''''''\n",
    "            toget = toget.view(1,-1)\n",
    "            # get list of used atoms i.e NNP's\n",
    "            #used_atoms = []\n",
    "            #for atom in range(23):\n",
    "            #    if(Atomic_Num[molecule][atom]!=0):\n",
    "            #        used_atoms.append(Atomic_Num[molecule][atom])\n",
    "            #used_atoms = np.unique(np.array(used_atoms))\n",
    "            \n",
    "            # if no nets were used, just move on to the next molecule\n",
    "            #if(len(used_atoms)==0) :\n",
    "             #   print(\"scream\")\n",
    "             #   break\n",
    "            \n",
    "            ''''''\n",
    "            # use loss function\n",
    "            loss = criterion(outp,toget)\n",
    "\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            \n",
    "            # step only the used optimizers            \n",
    "            #for atom in used_atoms:\n",
    "            #    optimizers[atom-1].step()    \n",
    "            ''''''\n",
    "            for atom in range(5) :\n",
    "                optimizers[atom].step()\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    losses = []\n",
    "    answ = 0\n",
    "    for mole in range(5501,7100) :\n",
    "        molecule = int(rans[int(mole)])\n",
    "        molecule = mole\n",
    "        \n",
    "\n",
    "        molecule_out = torch.zeros(1,1)\n",
    "        for atom in range(23):\n",
    "            #print(Atomic_Num[molecule][atom], end=\" \")\n",
    "            if(Atomic_Num[molecule][atom]==0):\n",
    "                continue\n",
    "            aev = torch.from_numpy((AEVs[molecule][atom]))\n",
    "            net_out = nets[Atomic_Num[molecule][atom]-1](aev.float())\n",
    "            #print(net_out)\n",
    "            molecule_out = molecule_out + net_out\n",
    "        #print(\"\")\n",
    "        \n",
    "        \n",
    "\n",
    "        targett = Target[molecule]\n",
    "        targett = torch.from_numpy(np.array(targett))\n",
    "        targett = targett.float()\n",
    "        targett = targett.view(1, -1)\n",
    "        #losses.append(targett - molecule_out)\n",
    "        loss = criterion(molecule_out, targett)\n",
    "        if ((targett-15) <= molecule_out <= (targett+15)) :\n",
    "            answ = answ + 1\n",
    "        if(molecule%10==0):\n",
    "            #print(\"molecule\")\n",
    "            #print(\"Target: \", targett)\n",
    "            #print(\"Our_vl: \", molecule_out)\n",
    "            #print(\"Loss  : \", loss)\n",
    "            #print(targett - molecule_out)\n",
    "            '''train(nets, optimizers, criterion)\n",
    "    testing(nets)\n",
    "    '''\n",
    "    #answ = sum(Los)\n",
    "    print(answ)\n",
    "    \n",
    "            \n",
    "    \n",
    "doNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for molecule in range(10):\n",
    "    for atom in range(23):\n",
    "        aev = []\n",
    "        for elem in AEVs[molecule][atom]:\n",
    "            if(elem>0.0000000001):\n",
    "                aev.append(elem)\n",
    "        print(aev)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
